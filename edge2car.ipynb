{"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"view-in-github"},"outputs":[],"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/davHub/edges2car/blob/master/cGAN.ipynb)"]},{"cell_type":"markdown","execution_count":2,"metadata":{},"outputs":[],"source":"# ***pix2pix implementation***"},{"cell_type":"markdown","execution_count":3,"metadata":{},"outputs":[],"source":"## Get data from drive"},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":196},"colab_type":"code","id":"WqcZHuBzr6Xw","outputId":"26de3462-a07f-4166-f911-78405a4d1e1e"},"outputs":[],"source":"!pip install pydrive\nfrom pydrive.auth import GoogleAuth\nfrom pydrive.drive import GoogleDrive\nfrom google.colab import auth\nfrom oauth2client.client import GoogleCredentials\n\n# 1. Authenticate and create the PyDrive client.\nauth.authenticate_user()\ngauth = GoogleAuth()\ngauth.credentials = GoogleCredentials.get_application_default()\ndrive = GoogleDrive(gauth)"},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"znaGPvxlsAbp"},"outputs":[],"source":"file_id = '18JHHTKNrxY40YdC5g70SBuBrmDwg1hVL'\ndownloaded = drive.CreateFile({'id': file_id})\ndownloaded.GetContentFile('cars_color.tar.gz')\n\n!tar -xf cars_color.tar.gz\n\n!mkdir processed\n!mkdir resized\n"},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"149V9CNx8Zof"},"outputs":[],"source":"file_id = '1neEd0g57M3IGDrIQCMGc7dY4Ezm7NpJS'\ndownloaded = drive.CreateFile({'id': file_id})\ndownloaded.GetContentFile('test_color_edge.tar.gz')\n\n!tar -xf test_color_edge.tar.gz\n\n#!mkdir processed\n#!mkdir resized\n"},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"colab_type":"code","id":"6h3DVmZbRcP5","outputId":"8a5b7290-ab50-4c32-a61e-adc21e63d4b0"},"outputs":[],"source":"file_id = '1qjIlr0jcmvj86pg_YG1Qg2wX86OMPGJW'\ndownloaded = drive.CreateFile({'id': file_id})\ndownloaded.GetContentFile('cars_new.tar')\n\n!tar -xf cars_new.tar\n\n!mkdir processed\n!mkdir resized"},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"2eZjJXuj59uj"},"outputs":[],"source":"!tar czvf data_car.tar.gz resized\n"},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"y7o0-aIj-sDX"},"outputs":[],"source":"drive_folder_id = '1MqdArcCnHnEQTp3gXEEPNqlm5aFWFIzf'\nname = \"model-23\"\n#name = \"6.jpg\"\n\ndef get_file_from_drive(folder_id, file_name):\n  file_list = drive.ListFile({'q': \"'\" + folder_id + \"' in parents and trashed=false\"}).GetList()\n  for file in file_list:\n    if file['title'] == file_name:\n      return file['id']\n\ndef upload_file_to_drive(file_name, file_data):\n  uploaded = drive.CreateFile({'title': file_name})\n  uploaded.SetContentString(file_data)\n  uploaded.Upload()\n  print('Uploaded file with ID {}'.format(uploaded.get('id')))\n  \ndef upload_data_system(name):\n  try:\n    downloaded = drive.CreateFile({'id': get_file_from_drive(drive_folder_id, name)})\n    downloaded.GetContentFile(name)\n  except Exception as err:\n      print(name, 'not found')\n      pass\n\ndef save_in_drive(name,folder_id = '1u6UBZpQuEz9xpqu2Fjre4jxj2XpYi843'):\n  file = drive.CreateFile({'parents':[{u'id': folder_id}]})\n  file.SetContentFile(name)\n  file.Upload()\n    \nupload_data_system(name+'.data-00000-of-00001')\nupload_data_system(name+'.index')\nupload_data_system(name+'.meta')\n#upload_data_system('vgg_16.ckpt')\n#save_in_drive('data_car.tar.gz', folder_id=drive_folder_id)\n\n#save_in_drive('checkpoint', folder_id=drive_folder_id)\n#save_in_drive(name+'.data-00000-of-00001', folder_id=drive_folder_id)\n#save_in_drive(name+'.index', folder_id=drive_folder_id)\n#save_in_drive(name+'.meta', folder_id=drive_folder_id)\n"},{"cell_type":"code","execution_count":54,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"colab_type":"code","id":"FX7euzulcSA-","outputId":"60721ed4-8582-4065-efb0-7d739ffe03fb"},"outputs":[],"source":"!rm processed/*\n!rm resized/*\n!rm tcar/*\n"},{"cell_type":"code","execution_count":99,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":501},"colab_type":"code","id":"F1UbqbXBe1ZC","outputId":"dd1050b4-d860-49c5-e51e-1df38870cc74"},"outputs":[],"source":"!ls\n!ls -l cars_new |wc -l\n!ls -l cars_color |wc -l\n!ls -l processed |wc -l\n!ls -l resized |wc -l\n!ls -l test |wc -l\n\n#!mkdir processed\n#!mkdir resized\n#!pip install Image\n#!ls edges2car"},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"lyOHjPTTDxj5"},"outputs":[],"source":"from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nimport pickle\nimport numpy as np\nimport tensorflow as tf\nimport json\nimport random\nimport math\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as draw\nimport cv2\nimport time\nfrom PIL import Image, ImageFilter, ImageOps, ImageEnhance\nfrom IPython.display import HTML, display\nimport os\nimport scipy.misc\nfrom glob import glob\n\nimport pickle\n\nfrom tensorflow.contrib.slim.nets import vgg\nslim = tf.contrib.slim\n\n"},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":"## Parameters"},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"92g5n76AD-r_"},"outputs":[],"source":"# data parameters\nupdate_data = True\n\nh=256\nw=256\n\n# Learning parameters\nEPOCHS = 50\nbatch_size = 1\ntest_batch_size = 5\nlearning_rate_d = 0.0002\nlearning_rate_g = 0.0002\ndropout = 0.5\nbeta1 = 0.5\n\ndf_dim = 64\ngf_dim = 64\n\nnew_network = True\ntrain = True\nratio_train = 0.95\n\n#k_initializer = tf.random_normal_initializer(0, 0.02)\nk_initializer = tf.contrib.layers.xavier_initializer()\n\nk_regulizer = tf.contrib.layers.l2_regularizer(scale=0.1)\n\nEPS = 1e-12"},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"x3F5GyWfi7-4"},"outputs":[],"source":"def display_img(img):\n  im = np.uint8(img)\n  plt.imshow(im)\n  plt.axis('off')\n  plt.show()"},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":"## Preprocessing data and Data Augmentation"},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":126},"colab_type":"code","id":"404ieKMtfKPJ","outputId":"d4421a34-1182-41e6-9c78-cada46514d89"},"outputs":[],"source":"step = 30\ndef Norme(p1,p2,p3,p4):\n    n = math.sqrt((p1[0]-p3[0])*(p1[0]-p3[0]) + (p2[0]-p4[0])*(p2[0]-p4[0]))    \n    return n\n\ndef get_contours(img, lib=None,seuil=50):\n  w,h,c = img.shape\n  imgC = None\n  if lib is 'CV2' :\n    imgC = cv2.Canny(img,w,h)\n    #imgC = cv2.bitwise_not(imgC)\n  elif lib is 'PIL':\n    imgC = Image.fromarray(img.astype('uint8'), 'RGB')\n    imgC = imgC.filter(ImageFilter.CONTOUR)\n  else :\n    imgP = Image.fromarray(img.astype('uint8'), 'RGB')\n    imgC = Image.new(imgP.mode,imgP.size)\n    for i in range(1,ligne-1):\n      for j in range(1,colonne-1):\n        p1 = imgP.getpixel((j-1,i))\n        p2 = imgP.getpixel((j,i-1))\n        p3 = imgP.getpixel((j+1,i))\n        p4 = imgP.getpixel((j,i+1))\n        n = Norme(p1,p2,p3,p4)\n        if n < seuil:\n          p = (255,255,255)\n        else:\n          p = (0,0,0)\n        imgC.putpixel((j-1,i-1),p)\n\n  return np.asarray(imgC)\n  \ndef get_car_color(img, l=5):\n  taux = 25\n  w,h,c = img.shape\n  start_w = int(w/2)\n  start_h = int(h/2)\n  \n  #imr = img[start_w:start_w+l,start_h:start_h+l,0] // taux\n  #print(imr)\n  #cr = np.reshape(imr,(l*l,))\n  #r = np.bincount(cr).argmax() * taux\n  #cg = np.reshape(img[start_w:start_w+l,start_h:start_h+l,1] // taux,(l*l,))\n  #g = np.bincount(cg).argmax() * taux\n  #cb = np.reshape(img[start_w:start_w+l,start_h:start_h+l,2] // taux,(l*l,))\n  #b = np.bincount(cb).argmax() * taux\n  \n  #color = [r,g,b]\n  \n  color = np.mean(np.mean(img[start_w:start_w+l,start_h:start_h+l,:],axis=0),axis=0)\n  \n  return color\n  \ndef is_white(color, seuil=230):\n  return color[0]>seuil and color[1]>seuil and color[2]>seuil\n\ndef is_bg_white(img, l=8):\n  w,h,c = img.shape\n  c = 0\n  window = []\n  window.append(img[0:l,0:l,:])\n  window.append(img[0:l,h-(2*l):h-(2*l)+l,:])\n  window.append(img[w-(2*l):w-(2*l)+l,0:l,:])\n  window.append(img[w-(2*l):w-(2*l)+l,h-(2*l):h-(2*l)+l,:])\n  for i in window:\n    color = np.mean(np.mean(i,axis=0),axis=0)\n    if is_white(color, seuil=230):\n      c+=1\n  \n  return c >2\n\ndef progress(value, max=100):\n  return HTML(\"\"\"\n        <progress\n            value='{value}'\n            max='{max}',\n            style='width: 100%'\n        >\n            {value}\n        </progress>\n  \"\"\".format(value=value, max=max))\n  \nprint('processing data')\nout = display(progress(0, 100), display_id=True)\nprog = 0\ncount = 0\ncountError=0\nNewFile =  glob(\"cars_new/*\")\nColorFile =  glob(\"cars_color/*\")\nImageFile = NewFile + ColorFile\nlength = len(ImageFile)\nfor idx, file in enumerate(ImageFile):\n    try:\n      img = Image.open(file)\n      img = img.resize((w, h),Image.ANTIALIAS)\n      colonne,ligne = img.size\n      img = np.asarray(img)\n      \n      if is_bg_white(img,l=10):\n        count +=1\n\n        edges = get_contours(img, lib='CV2', seuil=50)\n        color = get_car_color(img, l=2)\n\n        dim = edges.shape\n        #print(dim)\n        process_img = np.zeros((dim[0],dim[1],3),dtype='uint8')\n\n        #print(process_img.shape)\n\n        #process_img[:,:,0] = (1-edges/255)*color[0] \n        #process_img[:,:,1] = (1-edges/255)*color[1] \n        #process_img[:,:,2] = (1-edges/255)*color[2] \n\n        process_img[:,:,0] = np.where(edges/255 == 1, color[0],255) \n        process_img[:,:,1] = np.where(edges/255 == 1, color[1],255)\n        process_img[:,:,2] = np.where(edges/255 == 1, color[2],255) \n\n\n        #display_img(edges)\n        #display_img(process_img)\n        #display_img(img)\n\n        if idx%step ==0:\n          display_img(img[:,:,:3])\n          #display_img(edges[:,:,:3])\n          display_img(process_img[:,:,:3])\n\n        #print(type(process_img[0,0,0]),process_img[:,:,:3].shape)\n        #print(type(img[0,0,0]),img[:,:,:3].shape)\n\n        scipy.misc.imsave(\"processed/\"+file[9:], process_img[:,:,:3])\n        scipy.misc.imsave(\"resized/\"+file[9:], img[:,:,:3])\n    except (IOError,ValueError,KeyError):#,ValueError,KeyError, TypeError):\n      countError+= 1\n      #os.remove(file)\n    if prog % 17 ==0:\n      percent =  (prog+1) / length * 100\n      out.update(progress(percent, 100))\n    prog += 1\n    \n\ndata_dict = glob(\"processed/*\")\nrandom.shuffle(data_dict)    \ntrain_data = data_dict[:int(ratio_train*len(data_dict))]\ntest_data =  data_dict[int(ratio_train*len(data_dict)):]\nprint(\"Nb image : \",len(data_dict))\nprint(len(train_data))\nprint(len(test_data))\n    \n"},{"cell_type":"code","execution_count":0,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34895},"colab_type":"code","id":"XsrRHOzixAiW","outputId":"0e047a6b-b2a9-4def-9e98-ea246d9661ec"},"outputs":[],"source":"\ncountError = 0\nImageFile =  glob(\"resized/*\")\nfor idx, file in enumerate(ImageFile):\n    try:\n      img0 = Image.open(file)\n      img = np.asarray(img0)\n      color = get_color(img)\n      \n      edges = plt.imread(\"nb1/\"+file[8:])\n      \n      lim = 200\n      \n      e = edges.copy()\n      \n      posB = np.where(np.mean(edges, axis=2)<lim)\n      e[posB] = [255,255,255]\n      posC = np.where(np.mean(edges, axis=2)>lim)\n      e[posC]=color\n      \n      if idx%70 ==0:\n        display_img(img)\n        display_img(edges)\n        display_img(e)\n    except (IOError,ValueError):\n       countError+= 1#print(\"ERROR\")\n    img0.close()\n\n    \nprint(\"Error \" + str(countError))\n\n"},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":296},"colab_type":"code","id":"oqWwCco9gqSR","outputId":"429376f4-e324-43b1-ed07-e167863da638"},"outputs":[],"source":"!ls\nname = '85.jpg'\nimg = Image.open('cars_new/'+name)\nimg = np.asarray(img)\nplt.imshow(img)\nplt.axis('off')\nplt.show()"},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":71},"colab_type":"code","id":"WEztwo1xQy7F","outputId":"50a68f7e-c680-4dfa-9e64-18d84b9382bf"},"outputs":[],"source":"\ndata_dict = glob(\"processed/*\")\nrandom.shuffle(data_dict)    \ntrain_data = data_dict[:int(ratio_train*len(data_dict))]\ntest_data =  data_dict[int(ratio_train*len(data_dict)):]\nprint(\"Nb image : \",len(data_dict))\nprint(len(train_data))\nprint(len(test_data))"},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"tUVvcZnQjqtE"},"outputs":[],"source":"def preprocess(img):\n  # [0,1] => [-1,1]\n  return np.float32(img)/255 * 2 - 1\n\ndef deprocess(img):\n  # [-1, 1] => [0, 1]\n  return np.uint8(255.*((img+1.)/2))\n"},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"v4AhZMMwhO8d"},"outputs":[],"source":"def get_image(file):\n  img = plt.imread(file)\n  out = preprocess(img[:,:,:3])\n  return out\n\ndef next_batch_2(batch_size, index):\n  batch = [ get_image(\"processed/\"+batch_file[10:]) for batch_file in train_data[index*batch_size:(index+1)*batch_size]]\n  label = [ get_image(\"resized/\"+batch_file[10:]) for batch_file in train_data[index*batch_size:(index+1)*batch_size]]\n  return np.array(batch).astype(np.float32), np.array(label).astype(np.float32)\n\ndef next_batch(batch_size, index, training=True):\n  inputs = []\n  targets = []\n  #print(\"Batch from : \" + str(cb))\n  \n  t = train_data if training else test_data\n  batch_files = t[index*batch_size:(index+1)*batch_size]\n  if training :\n    for name in batch_files:\n        file = name[10:]\n        inp = plt.imread(\"processed/\"+file)\n        \n        inp = preprocess(inp[:,:,:3])\n        #print(type(inp[0,0,0]),inp.shape)\n        inputs.append(inp)\n\n        tar = plt.imread(\"resized/\"+file)\n        tar = preprocess(tar[:,:,:3])\n        targets.append(tar)\n        \n    return inputs, targets\n  \n  else :\n    for name in batch_files:\n      file = name[5:]\n      img = plt.imread(\"tcar/\"+file)\n      #print(img)\n      inp = preprocess(img[:,:,:3])\n      inputs.append(inp)\n    return inputs\n"},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"H1BrbbwESn9N"},"outputs":[],"source":"global_step = 0"},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":"## pix2pix Architecture"},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"EmdDiYwuSotG"},"outputs":[],"source":"def discriminator(inputs, targets, reuse=False, training=True):\n  with tf.variable_scope(\"discriminator\", reuse=reuse):\n    # image is 256 x 256 x (input_c_dim + output_c_dim)\n   \n    input = tf.concat([inputs, targets], axis=3)\n    print(input)\n    l = tf.layers.conv2d(input, df_dim, 4, strides=(2,2), activation=tf.nn.leaky_relu, padding='same', kernel_initializer=k_initializer, kernel_regularizer= k_regulizer)\n    print(l)\n\n    l = tf.layers.conv2d(l, df_dim*2, 4, strides=(2,2), activation=tf.nn.leaky_relu, padding='same', kernel_initializer=k_initializer, kernel_regularizer= k_regulizer)\n    print(l)\n    l = tf.layers.batch_normalization(l, training=True) \n\n    l = tf.layers.conv2d(l, df_dim*4, 4, strides=(2,2), activation=tf.nn.leaky_relu, padding='same', kernel_initializer=k_initializer, kernel_regularizer= k_regulizer)\n    print(l)\n    l = tf.layers.batch_normalization(l, training=True)\n\n    l = tf.layers.conv2d(l, df_dim*8, 4, strides=(1,1), activation=tf.nn.leaky_relu, padding='same', kernel_initializer=k_initializer, kernel_regularizer= k_regulizer)\n    print(l)\n    l = tf.layers.batch_normalization(l, training=True) \n\n    l = tf.layers.conv2d(l, df_dim*8, 3, strides=(1,1), activation=tf.nn.leaky_relu, padding='valid', kernel_initializer=k_initializer, kernel_regularizer= k_regulizer)\n    print(l)\n    l = tf.layers.conv2d(l, 1, 3, strides=(1,1), padding='valid', kernel_initializer=k_initializer, kernel_regularizer= k_regulizer)\n    print(l)\n    \n\n    return tf.nn.sigmoid(l), l\n"},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"dhcTmg6SD2rg"},"outputs":[],"source":"def encoder(inputs):\n  # encoding\n  print(inputs)\n  e1 = tf.layers.conv2d(inputs, gf_dim, 4, strides=(2,2), activation=None, padding='same', kernel_initializer=k_initializer, kernel_regularizer= k_regulizer)\n  print(e1) \n  e2 = tf.layers.conv2d(e1, gf_dim*2, 4, strides=(2,2), activation=tf.nn.leaky_relu, padding='same', kernel_initializer=k_initializer, kernel_regularizer= k_regulizer)\n  print(e2)\n  e2 = tf.layers.batch_normalization(e2, training=True) \n  \n  e3 = tf.layers.conv2d(e2, gf_dim*4, 4, strides=(2,2), activation=tf.nn.leaky_relu, padding='same', kernel_initializer=k_initializer, kernel_regularizer= k_regulizer)\n  print(e3)\n  e3 = tf.layers.batch_normalization(e3, training=True) \n \n  e4 = tf.layers.conv2d(e3, gf_dim*8, 4, strides=(2,2), activation=tf.nn.leaky_relu, padding='same', kernel_initializer=k_initializer, kernel_regularizer= k_regulizer)\n  print(e4)\n  e4 = tf.layers.batch_normalization(e4, training=True) \n \n  e5 = tf.layers.conv2d(e4, gf_dim*8, 4, strides=(2,2), activation=tf.nn.leaky_relu, padding='same', kernel_initializer=k_initializer, kernel_regularizer= k_regulizer)\n  print(e5)\n  e5 = tf.layers.batch_normalization(e5, training=True) \n  e6 = tf.layers.conv2d(e5, gf_dim*8, 4, strides=(2,2), activation=tf.nn.leaky_relu, padding='same', kernel_initializer=k_initializer, kernel_regularizer= k_regulizer)\n  print(e6)\n  e6 = tf.layers.batch_normalization(e6, training=True) \n \n  e7 = tf.layers.conv2d(e6, gf_dim*8, 4, strides=(2,2), activation=tf.nn.leaky_relu, padding='same', kernel_initializer=k_initializer, kernel_regularizer= k_regulizer)\n  print(e7)\n  e7 = tf.layers.batch_normalization(e7, training=True) \n \n  e8 = tf.layers.conv2d(e7, gf_dim*8, 4, strides=(2,2), activation=tf.nn.leaky_relu, padding='same', kernel_initializer=k_initializer, kernel_regularizer= k_regulizer)\n  print(e8)\n  e8 = tf.layers.batch_normalization(e8, training=True) \n  \n  return e1,e2,e3,e4,e5,e6,e7,e8\n \n"},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"IGpvLEaWFTSL"},"outputs":[],"source":"def decoder(inputs):\n  \n  e1,e2,e3,e4,e5,e6,e7,e8 = inputs\n  \n  d8=tf.layers.conv2d_transpose(e8, gf_dim*8, kernel_size=4, strides=(2,2), activation=tf.nn.relu, padding=\"same\", kernel_initializer=k_initializer)\n  print(d8)\n  d8 = tf.layers.batch_normalization(d8, training=True) \n  d8 = tf.nn.dropout(d8, keep_prob=1 - dropout)\n  \n  i = tf.concat([d8,e7], axis=3)\n  d7=tf.layers.conv2d_transpose(i, gf_dim*8, kernel_size=4, strides=(2,2), activation=tf.nn.relu, padding=\"same\", kernel_initializer=k_initializer)\n  print(d7)\n  d7 = tf.layers.batch_normalization(d7, training=True) \n  d7 = tf.nn.dropout(d7, keep_prob=1 - dropout)\n  \n  i = tf.concat([d7,e6], axis=3)\n  d6=tf.layers.conv2d_transpose(i, gf_dim*8, kernel_size=4, strides=(2,2), activation=tf.nn.relu, padding=\"same\", kernel_initializer=k_initializer)\n  print(d6)\n  d6 = tf.layers.batch_normalization(d6, training=True) \n  d6 = tf.nn.dropout(d6, keep_prob=1 - dropout)\n  \n  i = tf.concat([d6,e5], axis=3)\n  d5=tf.layers.conv2d_transpose(i, gf_dim*8, kernel_size=4, strides=(2,2), activation=tf.nn.relu, padding=\"same\", kernel_initializer=k_initializer)\n  print(d5)\n  d5 = tf.layers.batch_normalization(d5, training=True) \n  \n  i = tf.concat([d5,e4], axis=3)\n  d4=tf.layers.conv2d_transpose(i, gf_dim*4, kernel_size=4, strides=(2,2), activation=tf.nn.relu, padding=\"same\", kernel_initializer=k_initializer)\n  print(d4)\n  d4 = tf.layers.batch_normalization(d4, training=True) \n  \n  i = tf.concat([d4,e3], axis=3)\n  d3=tf.layers.conv2d_transpose(i, gf_dim*2, kernel_size=4, strides=(2,2), activation=tf.nn.relu, padding=\"same\", kernel_initializer=k_initializer)\n  print(d3)\n  d3 = tf.layers.batch_normalization(d3, training=True) \n  \n  i = tf.concat([d3,e2], axis=3)\n  d2=tf.layers.conv2d_transpose(i, gf_dim, kernel_size=4, strides=(2,2), activation=tf.nn.relu, padding=\"same\", kernel_initializer=k_initializer)\n  print(d2)\n  d2 = tf.layers.batch_normalization(d2, training=True) \n  \n  i = tf.concat([d2,e1], axis=3)\n  d1=tf.layers.conv2d_transpose(i, 3, kernel_size=4, strides=(2,2), activation=None, padding=\"same\", kernel_initializer=k_initializer)\n  print(d1)\n  \n  return tf.tanh(d1)\n"},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"saN7ferWbOJp"},"outputs":[],"source":"def generator(inputs):\n  with tf.variable_scope(\"generator\") as scope:\n    enc = encoder(inputs)\n    dec = decoder(enc)\n    return dec\n"},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"w0M4ZFImm65L"},"outputs":[],"source":"def model(inputs, targets):\n  \n  lambda_gen = 1.\n  lambda_L1 = 100.\n  \n  G = generator(inputs)\n  \n  D_real, D_real_logits = discriminator(targets,inputs, reuse=False)\n  D_fake, D_fake_logits = discriminator(G, inputs, reuse=True)\n  \n  #D loss\n  D_loss =  tf.reduce_mean(-(tf.log(D_real + EPS) + tf.log(1 - D_fake + EPS)))\n  \n  # G loss\n  G_loss_GAN = tf.reduce_mean(-tf.log(D_fake + EPS))\n  G_loss_L1 = tf.reduce_mean(tf.abs(targets - G))\n  \n  G_loss = lambda_gen * G_loss_GAN + lambda_L1 * G_loss_L1\n  \n  \n  t_vars = tf.trainable_variables()\n\n  D_vars = [var for var in t_vars if 'discriminator' in var.name]\n  G_vars = [var for var in t_vars if 'generator' in var.name]\n  \n  D_optim = tf.train.AdamOptimizer(learning_rate_d, beta1=beta1) \\\n                          .minimize(D_loss, var_list=D_vars)\n  G_optim = tf.train.AdamOptimizer(learning_rate_g, beta1=beta1) \\\n                          .minimize(G_loss, var_list=G_vars)\n\n  return D_loss, D_optim, G_loss, G_optim, G"},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"oPFJHqdf7t5L"},"outputs":[],"source":"def debug(epoch=None,step=None,loss=None, accuracy=None, time=None, name=\"\"):\n  debug=\"\"\n  if epoch is not None :\n    debug+=\"Epoch : [{}] - \".format(epoch)\n  \n  if step is not None :\n    debug+=\"Step : [{}] - \".format(step)\n  \n  if time is not None :\n    debug+=\"Time : %4.2f min\\n\" % (time/60000)\n  if loss is not None :\n    debug += \"\"\n    debug += name +\" - \"\n  \n    debug+=\"Loss : {} - \".format(loss)\n  \n  if accuracy is not None :\n    debug+=\"Accuracy : {}\".format(accuracy)\n    \n  return debug \n"},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":"## Training"},{"cell_type":"code","execution_count":92,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":12228},"colab_type":"code","id":"g7PYxr2SotIa","outputId":"6dd6b100-756d-40a2-896f-9478b030ec45"},"outputs":[],"source":"tf.reset_default_graph()\nprint(\"Init Tensors\")\ngraph = tf.Graph()\nwith graph.as_default():\n  inputs = tf.placeholder( tf.float32, shape=[batch_size]+[256, 256, 3] )\n  targets = tf.placeholder( tf.float32 , shape=[batch_size]+[256, 256, 3])\n  \n  discrim_loss, discrim_optim, gen_loss, gen_optim, gen_predict = model(inputs,targets)\n  \n  saver = tf.train.Saver(max_to_keep=6)\n\n  \nprint(\"Start Training\")\nwith tf.Session(graph=graph) as sess:\n  if False:\n    sess.run(tf.global_variables_initializer())\n    global_step = 0\n  else:\n    saver.restore(sess, tf.train.latest_checkpoint('./'))\n    #saver.restore(sess, 'model-10')\n\n  num_batches = int(len(train_data)/batch_size)\n  print(num_batches)\n  start_time = time.time()\n  for epoch in range(EPOCHS):\n    random.shuffle(train_data)\n    for step in range(num_batches):\n  \n      train_inputs, train_targets = next_batch(batch_size, step)\n      #print(type(train_inputs),len(train_inputs))\n      #print(type(train_targets),train_targets)\n     \n      _ , D_loss = sess.run([discrim_optim, discrim_loss], feed_dict={\n          inputs: train_inputs,\n          \n          targets: train_targets\n      })\n      \n      _ , G_loss = sess.run([gen_optim, gen_loss], feed_dict={\n          inputs: train_inputs,\n          targets: train_targets\n      })\n      \n      _ , G_loss = sess.run([gen_optim, gen_loss], feed_dict={\n          inputs: train_inputs,\n          targets: train_targets\n      })\n      \n      if step%(num_batches//4)==0:\n        time_now = time.time()\n        debug_D = debug(epoch=epoch, time=time_now - start_time,step = step, loss=D_loss,name=\"Dicriminator\")\n        print(debug_D)\n        debug_G = debug(loss=G_loss,name=\"Generator\")\n        print(debug_G)\n\n      if step% (num_batches//3) == 0 :\n        G_predict = sess.run([gen_predict], feed_dict={\n          inputs: train_inputs\n        })\n        \n        #display_img(deprocess(train_targets[0]))\n        display_img(deprocess(G_predict[0][0]))\n\n    if epoch%3 == 0 :\n      print(\"Saving model\")\n      saver.save(sess, \"./model\", global_step=global_step)\n\n    global_step = global_step + 1\n"},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":"## Testing"},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":4069},"colab_type":"code","id":"Q5Dc3Y33Xa-w","outputId":"d676eb40-2f52-45c6-8083-a8a97648f5b9"},"outputs":[],"source":"ImageFile =  glob(\"test_color_edge/*\")\nprint(ImageFile)\ncount_test=0\nfor idx, file in enumerate(ImageFile):\n    try:\n      img = Image.open(file)\n      img = img.resize((w, h),Image.ANTIALIAS)\n      img = np.asarray(img)\n      if len(img.shape)<3 or img.shape[0] is not w or img.shape[1] is not h :\n        continue\n      if idx%8 ==0:\n        display_img(img)\n\n      \n      scipy.misc.imsave(\"tcar/\"+file[16:], img)\n      count_test +=1\n    except (IOError,ValueError,KeyError):\n      countError+= 1\n      \nprint(count_test)"},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":698},"colab_type":"code","id":"le7Ke5f7XzLg","outputId":"74baf565-be05-4d6f-c4ac-ef44b8d73937"},"outputs":[],"source":"!ls\n!mkdir tcar\n#!rm tcar/*\n!ls test_color_edge\n#!rm -r test_color_edge"},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":15315},"colab_type":"code","id":"j3yzgVyoOboJ","outputId":"40de2656-f034-4316-bf3e-b27b0e7d3669"},"outputs":[],"source":"test_batch_size =1\n\ntest_data = glob(\"tcar/*6*\")\nprint(len(test_data))\n\nshow =5\n\ntf.reset_default_graph()\nprint(\"Init Tensors\")\ngraph = tf.Graph()\nwith graph.as_default():\n  inputs = tf.placeholder( tf.float32, shape=[test_batch_size]+[h, w, 3] )\n  targets = tf.placeholder( tf.float32 , shape=[test_batch_size]+[h, w, 3])\n  \n  discrim_loss, discrim_optim, gen_loss, gen_optim, gen_predict = model(inputs,targets)\n  \n  saver = tf.train.Saver(max_to_keep=4)\n\n  \nprint(\"Start Training\")\nwith tf.Session(graph=graph) as sess:\n  #saver.restore(sess, tf.train.latest_checkpoint('./'))\n  saver.restore(sess, 'model-23')\n\n  num_batches = int(len(test_data)/test_batch_size)\n  print(num_batches)\n  start_time = time.time()\n  random.shuffle(test_data)\n  for step in range(num_batches):\n    test_inputs = next_batch(test_batch_size, step,training=False)\n    G_predict = sess.run(gen_predict, feed_dict={\n        inputs: test_inputs\n    })\n    display_img(deprocess(test_inputs[0]))\n    display_img(deprocess(G_predict[0]))"}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}